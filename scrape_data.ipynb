{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976d014f",
   "metadata": {},
   "source": [
    "## Goal: Predict Peak Times in the DHBW Cafeteria Using Calendar Data\n",
    "\n",
    "This notebook integrates and analyzes external calendar data (e.g., public holidays, lecture schedules, exam periods) to improve the prediction of peak hours in the DHBW cafeteria. By identifying patterns in visitor behavior, we aim to support better planning for both cafeteria staff and students.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a81af10",
   "metadata": {},
   "source": [
    "### Funktion scrape_rapla_calendar\n",
    "\n",
    "Scrape the Rapla calendar HTML for a given user & file (course).\\\n",
    "Optionally filter calendar week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea78460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_fields(title_text: str) -> dict:\n",
    "    fields = {\n",
    "        \"veranstaltungstitel\": None,\n",
    "        \"sprache\": None,\n",
    "        \"studiengang\": None,\n",
    "        \"anzahl_studierende\": None,\n",
    "        \"geplante_vorlesungsstunden\": None,\n",
    "        \"planungsnotiz\": None,\n",
    "        \"ressourcen\": None,\n",
    "        \"personen\": None,\n",
    "    }\n",
    "\n",
    "    # Wenn der Titel NICHT mit 'Lehrveranstaltung' beginnt → nimm erste Zeile als Veranstaltungstitel\n",
    "    if not title_text.strip().lower().startswith(\"lehrveranstaltung\"):\n",
    "        first_line = title_text.strip().split(\"\\n\")[0]\n",
    "        fields[\"veranstaltungstitel\"] = first_line.strip()\n",
    "        return fields\n",
    "\n",
    "    # Andernfalls: Extrahiere strukturierte Informationen\n",
    "    def extract(label):\n",
    "        pattern = rf\"{label}:\\s*\\n*(.*?)\\n\\n\"\n",
    "        match = re.search(pattern, title_text, re.DOTALL | re.IGNORECASE)\n",
    "        return match.group(1).strip() if match else None\n",
    "\n",
    "    fields[\"veranstaltungstitel\"] = extract(\"Titel\")\n",
    "    fields[\"sprache\"] = extract(\"Sprache\")\n",
    "    fields[\"studiengang\"] = extract(\"Studiengang\")\n",
    "    fields[\"anzahl_studierende\"] = extract(\"Anzahl Studierende\")\n",
    "    fields[\"geplante_vorlesungsstunden\"] = extract(\"Gepl\\. Vorlesungsstunden\")\n",
    "    fields[\"planungsnotiz\"] = extract(\"Planungsnotiz\")\n",
    "\n",
    "    res_match = re.search(r\"Ressourcen:\\s*\\n(.*?)\\n\\n\", title_text, re.DOTALL)\n",
    "    if res_match:\n",
    "        ressourcen = res_match.group(1).strip().replace(\"\\n\", \",\")\n",
    "        fields[\"ressourcen\"] = ressourcen\n",
    "\n",
    "    personen_match = re.search(r\"Personen:\\s*\\n(.*?)\\n\\n\", title_text, re.DOTALL)\n",
    "    if personen_match:\n",
    "        personen_block = personen_match.group(1).strip()\n",
    "        personen = list({line.strip() for line in personen_block.split(\"\\n\") if line.strip()})\n",
    "        fields[\"personen\"] = \", \".join(personen)\n",
    "\n",
    "    return fields\n",
    "\n",
    "\n",
    "def scrape_rapla_calendar(user: str, file: str, day: int = None, month: int = None, year: int = None):\n",
    "    base_url = \"https://rapla.dhbw-karlsruhe.de/rapla\"\n",
    "    params = {\n",
    "        \"page\": \"calendar\",\n",
    "        \"user\": user,\n",
    "        \"file\": file\n",
    "    }\n",
    "\n",
    "    if day and month and year:\n",
    "        params.update({\n",
    "            \"day\": day,\n",
    "            \"month\": month,\n",
    "            \"year\": year\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        resp = requests.get(base_url, params=params)\n",
    "        resp.raise_for_status()  # Raise an exception for bad status codes\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        text = soup.get_text(separator=\"\\n\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()  # Or raise the exception if you want the program to stop\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"(?P<start>\\d{2}:\\d{2})\\s*-\\s*(?P<end>\\d{2}:\\d{2})\\s+\"\n",
    "        r\"(?P<title>.*?)(?:\\n|\\s)+\"\n",
    "        r\"(?P<weekday>Mo|Di|Mi|Do|Fr|Sa|So)\\s+\"\n",
    "        r\"(?P<date>\\d{2}\\.\\d{2}\\.\\d{2})\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    events = []\n",
    "    for m in pattern.finditer(text):\n",
    "        try:\n",
    "            dd, mm, yy = m.group(\"date\").split(\".\")\n",
    "            iso_date = f\"20{yy}-{mm}-{dd}\"\n",
    "            title_raw = m.group(\"title\").strip()\n",
    "\n",
    "            extracted = extract_fields(title_raw)\n",
    "\n",
    "            event = {\n",
    "                \"title\": title_raw,\n",
    "                \"start\": f\"{iso_date} {m.group('start')}\",\n",
    "                \"end\": f\"{iso_date} {m.group('end')}\",\n",
    "                \"weekday\": m.group(\"weekday\"),\n",
    "                \"raw_date\": m.group(\"date\"),\n",
    "            }\n",
    "            event.update(extracted)\n",
    "            events.append(event)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing event: {e}, text: {m.group(0)}\")\n",
    "            continue  # Skip to the next event\n",
    "\n",
    "    df = pd.DataFrame(events)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Warning: No events found for this period.\")\n",
    "        return df  # Or handle as appropriate\n",
    "\n",
    "    try:\n",
    "        df[\"start\"] = pd.to_datetime(df[\"start\"])\n",
    "        df[\"end\"] = pd.to_datetime(df[\"end\"])\n",
    "        df[\"date\"] = df[\"start\"].dt.date\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e}.  Columns in DataFrame: {df.columns}\")\n",
    "        return df  # Or handle the error as needed\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "320c41b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def get_monday_of_week(year: int, week: int) -> datetime.date:\n",
    "    # ISO Kalender: Montag als erster Tag der Woche\n",
    "    # ISO-Woche 1: die Woche mit dem ersten Donnerstag\n",
    "    return datetime.datetime.strptime(f'{year}-W{week:02d}-1', \"%Y-W%W-%w\").date()\n",
    "\n",
    "def scrape_full_year(user: str, file: str, year: int = 2025):\n",
    "    all_dfs = []\n",
    "    max_week = 53  # max. KW, 2025 hat 53 Wochen laut ISO-Kalender\n",
    "\n",
    "    for week in range(1, max_week + 1):\n",
    "        try:\n",
    "            monday = get_monday_of_week(year, week)\n",
    "        except ValueError:\n",
    "            # Manche Kombinationen können nicht existieren, z.B. KW 53 in manchen Jahren\n",
    "            continue\n",
    "\n",
    "        print(f\"Scraping Woche {week}, Startdatum {monday}\")\n",
    "        df_week = scrape_rapla_calendar(\n",
    "            user=user,\n",
    "            file=file,\n",
    "            day=monday.day,\n",
    "            month=monday.month,\n",
    "            year=monday.year,\n",
    "        )\n",
    "        all_dfs.append(df_week)\n",
    "\n",
    "    # Alle DataFrames zusammenführen\n",
    "    full_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"Gesamter Kalender für {year} gespeichert als kalender_{year}_gesamt.csv\")\n",
    "    return full_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d7842190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Woche 1, Startdatum 2025-01-06\n",
      "Scraping Woche 2, Startdatum 2025-01-13\n",
      "Scraping Woche 3, Startdatum 2025-01-20\n",
      "Scraping Woche 4, Startdatum 2025-01-27\n",
      "Scraping Woche 5, Startdatum 2025-02-03\n",
      "Scraping Woche 6, Startdatum 2025-02-10\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m full_calendar_df \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_full_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbrockmans\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWWI22B1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2025\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m full_calendar_df\n",
      "Cell \u001b[1;32mIn[66], line 20\u001b[0m, in \u001b[0;36mscrape_full_year\u001b[1;34m(user, file, year)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping Woche \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweek\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Startdatum \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonday\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     df_week \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_rapla_calendar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mday\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonday\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mday\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonday\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43myear\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonday\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     all_dfs\u001b[38;5;241m.\u001b[39mappend(df_week)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Alle DataFrames zusammenführen\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[62], line 100\u001b[0m, in \u001b[0;36mscrape_rapla_calendar\u001b[1;34m(user, file, day, month, year)\u001b[0m\n\u001b[0;32m     97\u001b[0m     events\u001b[38;5;241m.\u001b[39mappend(event)\n\u001b[0;32m     99\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(events)\n\u001b[1;32m--> 100\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstart\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    101\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    102\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate\n",
      "File \u001b[1;32mc:\\Users\\I569961\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\I569961\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'start'"
     ]
    }
   ],
   "source": [
    "full_calendar_df = scrape_full_year(user=\"brockmans\", file=\"WWI22B1\", year=2025)\n",
    "full_calendar_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
